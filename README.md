# Gemini DuckDB Data Analyzer

Gemini APIとDuckDBを組み合わせた、AI駆動のデータ分析ツールです。CSVファイルをアップロードして、自然言語でデータに関する質問をすることができます。

## 🎯 プロジェクトの趣旨

このプロジェクトは以下の目的で開発されました：

- **AI駆動データ分析**: Gemini APIを使用して、自然言語でデータに関する質問に回答
- **高速データ処理**: DuckDBを使用した高速なCSVデータ読み込みと処理
- **インタラクティブな可視化**: PyGWalkerを使用したデータの可視化機能
- **ユーザーフレンドリー**: Streamlitによる直感的なWebインターフェース

## ✨ 主な機能

- **CSVファイルアップロード**: 任意のCSVファイルをアップロードして分析
- **AI質問応答**: 自然言語でデータに関する質問を投げかけ、AIが回答
- **データ可視化**: PyGWalkerによるインタラクティブなデータ可視化
- **リアルタイム分析**: アップロードしたデータを即座に分析可能

## 🚀 起動方法

### 前提条件

- Docker と Docker Compose がインストールされていること
- Gemini APIキーを取得済みであること

### Gemini APIキーの作成
公式Geminiサイトや以下のチュートリアルを参考にAPIキーを作成してください。

[Gemini APIキーの作成方法](https://tech-useit-wealth.com/gemini-api-tutorial)

APIキーを作成したら、プロジェクトディレクトリに`.env`ファイルを作成し、以下のように記載します。

```
GOOGLE_API_KEY="your API key"
```

### Dockerの設定
このプロジェクトはDocker環境で簡単に動作するように設計されています。

#### Dockerイメージのビルド
まず、Dockerイメージをビルドします。この手順は、`Dockerfile`を変更しない限り1回だけ実行すれば十分です。

```
docker build -t gemini_recipe .
```

#### Dockerコンテナの起動
イメージのビルドが完了したら、以下のコマンドでコンテナを作成・起動します。

```
docker compose up -d
```

コンテナのシェルにアクセスするには、以下を実行してください。

```
docker exec -it gemini_recipe bash
```

ここから、必要に応じてPythonスクリプトを実行できます（詳細は後述）。

#### Dockerの終了
コンテナシェルを終了するには以下を実行します。

```
exit
```

コンテナを停止するには以下を実行します。

```
docker compose down
```

## Pythonスクリプトの実行

### Streamlitアプリケーション
`gemini_agent.py`はStreamlitアプリです。以下のコマンドで起動します。

```
streamlit run gemini_agent.py
```

### アプリケーションへのアクセス

ブラウザで以下のURLにアクセスしてください：
```
http://localhost:8501
```

### 使用方法

1. **CSVファイルのアップロード**: サイドバーの「CSVファイルをアップロードしてください」からファイルを選択
2. **データの可視化**: アップロード後、PyGWalkerによるインタラクティブな可視化が利用可能
3. **AI質問**: サイドバーのテキストエリアに質問を入力（例：「データセットの概要を解説してください」）
4. **実行**: 「Agentの実行」ボタンをクリックしてAIの回答を取得

## 🛠️ 技術スタック

- **Python 3.11.11**: メインのプログラミング言語
- **Streamlit**: Webアプリケーションフレームワーク
- **DuckDB**: 高速な列指向データベース
- **Gemini API**: Googleの生成AIAPI
- **LangChain**: AIエージェントフレームワーク
- **PyGWalker**: データ可視化ライブラリ
- **Docker**: コンテナ化技術

## 📄 ライセンス

このプロジェクトはMITライセンスの下で公開されています。詳細は `LICENSE` ファイルを参照してください。
